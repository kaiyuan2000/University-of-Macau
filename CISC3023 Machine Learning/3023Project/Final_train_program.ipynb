{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb487085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import argparse\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8046bff6",
   "metadata": {},
   "source": [
    "This is Training Program, \n",
    "main program is to run the trainData() function. \n",
    "Note : change training_data_directory to the actual training dataset.\n",
    "\n",
    "Input : training_data\n",
    "Output : will dump out model to device for testing purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01986106",
   "metadata": {},
   "source": [
    "We will use training data to train 3 models with best parameter possible. Each model will show its training accuracy, validation accuracy, fitting duration, confusion matrix, cross validation score, cross validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35a902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_directory = \"/Users/kaiyuan/Desktop/3023Project/TrafficSignData/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f387949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from skimage import exposure\n",
    "\n",
    "def readTrafficSigns(rootpath):\n",
    "    '''Reads traffic sign data \n",
    "    Arguments: path to the traffic sign data, for example './TrafficSignData/Training'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over N classes, at most we have 42 classes\n",
    "    N=15\n",
    "    for c in range(0,N):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        #gtReader.next() # skip header\n",
    "        next(gtReader)\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            img=Image.open(prefix + row[0])  # the 1th column is the filename\n",
    "            # preprocesing image, make sure the images are in the same size\n",
    "            img=img.resize((32,32), Image.BICUBIC)\n",
    "            \n",
    "            img=np.array(img)\n",
    "            img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            img=exposure.equalize_adapthist(img,clip_limit=0.1)\n",
    "            images.append(img) \n",
    "            labels.append(row[7]) # the 8th column is the label\n",
    "        gtFile.close()\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66ff447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.10\n",
    "\n",
    "def loadData():\n",
    "    trainImages, trainLabels = readTrafficSigns(training_data_directory)\n",
    "    print('number of historical data=', len(trainLabels))\n",
    "    # design the input and output for model\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for i in range(0,len(trainLabels)):\n",
    "        # input X just the flattern image\n",
    "        X.append(trainImages[i].flatten())\n",
    "        Y.append(int(trainLabels[i]))\n",
    "    X=np.array(X)\n",
    "    Y=np.array(Y)\n",
    "    print(f\"shape of X : {np.shape(X)}\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,Y, test_size=TEST_SIZE)\n",
    "    print(f\"shape of X_train : {np.shape(X_train)}\")\n",
    "    print(f\"length of training data : {len(X_train)}.\")\n",
    "    print(f\"length of validation data : {len(X_val)}.\")\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae1e4cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of historical data= 15540\n",
      "shape of X : (15540, 1024)\n",
      "shape of X_train : (13986, 1024)\n",
      "length of training data : 13986.\n",
      "length of validation data : 1554.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4152911b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier, training accuracy: 1.000, validation accuracy: 0.950\n",
      "Fitting Duration (seconds) :8.22s\n",
      "Confusion Matrix :\n",
      "[[ 15   1   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 129   3   0   1   0   0   1   1   0   0   0   0   0   0]\n",
      " [  0   4 141   0   1   4   0   1   1   0   0   0   0   1   0]\n",
      " [  0   1   2  85   1   6   0   0   1   1   0   0   0   0   0]\n",
      " [  0   0   1   0 133   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   2   5   0   2 115   0   1   4   0   2   0   1   1   0]\n",
      " [  0   0   0   0   0   1  34   0   0   0   0   0   1   0   0]\n",
      " [  0   1   0   0   0   6   0  86   4   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   3  90   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2 108   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 115   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   0   0  94   0   0   0]\n",
      " [  0   0   1   0   0   0   0   1   0   1   0   0 134   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 146   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  52]]\n",
      "Cross-Validation-Scores: [0.94781987 0.94279585 0.94100822 0.94172327 0.94851627]\n",
      "MAX Cross-Validation-Score: 0.9485162674293887\n",
      "MIN Cross-Validation-Score: 0.9410082230961745\n",
      "Cross-Validation-Accuracy: 0.944373 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "# with BEST performance parameter (random forest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "randomForest = RandomForestClassifier(n_estimators=40, random_state=0,max_features = \"sqrt\")\n",
    "start_time = time.time()\n",
    "randomForest = randomForest.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_confusion_matrix = confusion_matrix(y_val,randomForest.predict(X_val))\n",
    "        \n",
    "print(\"RandomForestClassifier, training accuracy: %.3f, validation accuracy: %.3f\" % (\n",
    "    randomForest.score(X_train, y_train), randomForest.score(X_val, y_val)))\n",
    "print(f\"Fitting Duration (seconds) :{duration:.2f}s\")\n",
    "print(f\"Confusion Matrix :\")\n",
    "print(model_confusion_matrix)\n",
    "\n",
    "cv_scores = cross_val_score(randomForest, X_train, y_train, cv=5)\n",
    "print(\"Cross-Validation-Scores: \"+str(cv_scores))\n",
    "print(\"MAX Cross-Validation-Score: \"+str(max(cv_scores)))\n",
    "print(\"MIN Cross-Validation-Score: \"+str(min(cv_scores)))\n",
    "print(\"Cross-Validation-Accuracy: %.6f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b28ebe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, training accuracy: 1.000, validation accuracy: 0.984\n",
      "Fitting Duration (seconds) :62.4688s\n",
      "Confusion Matrix :\n",
      "[[ 17   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 130   3   0   0   1   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0 152   0   0   1   0   0   0   0   0   0   0   0   0]\n",
      " [  0   1   0  95   0   1   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2   0 132   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   1   1   0 128   0   1   0   0   0   0   0   2   0]\n",
      " [  0   0   0   0   0   0  36   0   0   0   0   0   0   0   0]\n",
      " [  0   1   3   0   0   1   0  92   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0  94   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 109   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 115   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  94   2   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 137   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 146   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  52]]\n",
      "Cross-Validation-Scores: [0.98320229 0.9792635  0.97676082 0.97854844 0.98283876]\n",
      "MAX Cross-Validation-Score: 0.9832022873481058\n",
      "MIN Cross-Validation-Score: 0.9767608151590991\n",
      "Cross-Validation-Accuracy: 0.980123 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "# with BEST performance parameter (SVM)\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel=\"rbf\", C=10.5)\n",
    "start_time = time.time()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "score = clf.score(X_val,y_val)\n",
    "model_confusion_matrix = confusion_matrix(y_val,clf.predict(X_val))\n",
    "\n",
    "\n",
    "print(\"SVM, training accuracy: %.3f, validation accuracy: %.3f\" % (\n",
    "    clf.score(X_train, y_train), clf.score(X_val, y_val)))\n",
    "print(f\"Fitting Duration (seconds) :{duration:.4f}s\")\n",
    "print(f\"Confusion Matrix :\")\n",
    "print(model_confusion_matrix)\n",
    "\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Cross-Validation-Scores: \"+str(cv_scores))\n",
    "print(\"MAX Cross-Validation-Score: \"+str(max(cv_scores)))\n",
    "print(\"MIN Cross-Validation-Score: \"+str(min(cv_scores)))\n",
    "print(\"Cross-Validation-Accuracy: %.6f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6930e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaiyuan/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP, training accuracy: 0.968, validation accuracy: 0.939\n",
      "Fitting Duration (seconds) :109.8117s\n",
      "Confusion Matrix :\n",
      "[[ 15   1   0   0   0   1   0   0   0   0   0   0   0   0   0]\n",
      " [  0 119   9   1   0   1   0   0   5   0   0   0   0   0   0]\n",
      " [  0   2 140   1   0   2   0   0   1   2   0   1   3   1   0]\n",
      " [  0   1   2  88   0   3   0   0   2   0   0   0   1   0   0]\n",
      " [  0   1   0   1 132   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   3   1   7   0 118   0   1   1   0   0   0   0   2   0]\n",
      " [  0   0   0   0   0   3  33   0   0   0   0   0   0   0   0]\n",
      " [  0   1   3   0   0   3   0  86   1   0   1   1   1   0   0]\n",
      " [  1   1   3   0   1   0   0   1  88   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   1   0   0   0 107   1   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0 114   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  95   1   0   0]\n",
      " [  0   1   1   1   0   0   0   1   0   0   2   1 130   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   1   1   0 143   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  51]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaiyuan/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/kaiyuan/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/kaiyuan/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/kaiyuan/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation-Scores: [0.93709793 0.92777976 0.92491956 0.93350018 0.93600286]\n",
      "MAX Cross-Validation-Score: 0.9370979270907791\n",
      "MIN Cross-Validation-Score: 0.9249195566678584\n",
      "Cross-Validation-Accuracy: 0.931860 (+/- 0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaiyuan/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#best paramter  (MLP)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='sgd', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100,), random_state=0)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "score = clf.score(X_val,y_val)\n",
    "model_confusion_matrix = confusion_matrix(y_val,clf.predict(X_val))\n",
    "\n",
    "print(\"MLP, training accuracy: %.3f, validation accuracy: %.3f\" % (\n",
    "    clf.score(X_train, y_train), clf.score(X_val, y_val)))\n",
    "print(f\"Fitting Duration (seconds) :{duration:.4f}s\")\n",
    "print(f\"Confusion Matrix :\")\n",
    "print(model_confusion_matrix)\n",
    "\n",
    "\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Cross-Validation-Scores: \"+str(cv_scores))\n",
    "print(\"MAX Cross-Validation-Score: \"+str(max(cv_scores)))\n",
    "print(\"MIN Cross-Validation-Score: \"+str(min(cv_scores)))\n",
    "print(\"Cross-Validation-Accuracy: %.6f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "954ebd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainData():\n",
    "    X_train, X_val, y_train, y_val = loadData()\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"Training Random Forest Model...\")\n",
    "    randomForest = RandomForestClassifier(n_estimators=40, random_state=0,max_features = \"sqrt\")\n",
    "    randomForest = randomForest.fit(X_train, y_train)\n",
    "    with open(\"FinalrandomForest.pkl\",\"wb\") as op_file:\n",
    "        pickle.dump(randomForest, op_file)\n",
    "    print(\"Done training Random Forest Model\")\n",
    "    print(\"Done dump model.\")\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    \n",
    "    print(\"Training SVM Model...\")\n",
    "    clf = svm.SVC(kernel=\"linear\",C=10.5)\n",
    "    clf.fit(X_train,y_train)\n",
    "    with open(\"finalsvm.pkl\",\"wb\") as op_file:\n",
    "        pickle.dump(clf, op_file)\n",
    "    print(\"Done training SVM Model\")\n",
    "    print(\"Done dump model.\")\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    \n",
    "    print(\"Training Random Forest Model...\")\n",
    "    clf = MLPClassifier(solver='sgd', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100,), random_state=0)\n",
    "    clf.fit(X_train,y_train)\n",
    "    with open(\"neuralnetwork.pkl\",\"wb\") as op_file:\n",
    "        pickle.dump(clf, op_file)\n",
    "    print(\"Done training MLP Model\")\n",
    "    print(\"Done dump model.\")\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"Finish training, can get your model at device.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdab8f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of historical data= 15540\n",
      "shape of X : (15540, 1024)\n",
      "shape of X_train : (13986, 1024)\n",
      "length of training data : 13986.\n",
      "length of validation data : 1554.\n",
      "---------------------------\n",
      "Training Random Forest Model...\n",
      "Done training Random Forest Model\n",
      "Done dump model.\n",
      "---------------------------\n",
      "Training SVM Model...\n",
      "Done training SVM Model\n",
      "Done dump model.\n",
      "---------------------------\n",
      "Training Random Forest Model...\n",
      "Done training MLP Model\n",
      "Done dump model.\n",
      "---------------------------\n",
      "Finish training, can get your model at device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaiyuan/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainData()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
